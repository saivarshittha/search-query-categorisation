{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "search-query-categorisation-BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84ecf1217a80427794e015aaba15142e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab18609848524d60b560f98bf17956e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_919ad4d604a24f25aa92f353c2cf9091",
              "IPY_MODEL_06ebfc9954ba460899610a2735d0aa33",
              "IPY_MODEL_131060a25c6c49768670232f2f3fc3b1"
            ]
          }
        },
        "ab18609848524d60b560f98bf17956e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "919ad4d604a24f25aa92f353c2cf9091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61562f1fe3f0488091c53a616e03a3b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0134b480b71b4bd5a812b4c46f7a051e"
          }
        },
        "06ebfc9954ba460899610a2735d0aa33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95caae28f57b4068a0d3d7785cc1baa2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13f5c169b5184bd7a0f7bf28cee623eb"
          }
        },
        "131060a25c6c49768670232f2f3fc3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e91a5ef386b48619161737847b7f5d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 5.23kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0481ce386ddf4ab9a3265c38e8e1b8e0"
          }
        },
        "61562f1fe3f0488091c53a616e03a3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0134b480b71b4bd5a812b4c46f7a051e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95caae28f57b4068a0d3d7785cc1baa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13f5c169b5184bd7a0f7bf28cee623eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e91a5ef386b48619161737847b7f5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0481ce386ddf4ab9a3265c38e8e1b8e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53d4f64da89148909592d87ba0f36e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2318fa58513146409eb8d99feb41542f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aa6b61fc6eb14dd38662496d6d0b0f64",
              "IPY_MODEL_0505de31b50b419fb0d56121b4b567c6",
              "IPY_MODEL_c3b2cdd328d9486d8f579569802f3bb3"
            ]
          }
        },
        "2318fa58513146409eb8d99feb41542f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa6b61fc6eb14dd38662496d6d0b0f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27434cfa966047878a6468b3d60d0e86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89bc47d095e042dca62a29ddb1111275"
          }
        },
        "0505de31b50b419fb0d56121b4b567c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e492a2c387147bcbb8c242dcce8efd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c93139262ef4914891df018e2d7dfa2"
          }
        },
        "c3b2cdd328d9486d8f579569802f3bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3391352b44e4495846f284a206babdb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:14&lt;00:00, 22.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24cf45a32a534558899f4f6b549a82b9"
          }
        },
        "27434cfa966047878a6468b3d60d0e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89bc47d095e042dca62a29ddb1111275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e492a2c387147bcbb8c242dcce8efd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c93139262ef4914891df018e2d7dfa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3391352b44e4495846f284a206babdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24cf45a32a534558899f4f6b549a82b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4929bceae594505ae228f3706eddfcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0078235319984b8297fda4f7ce2842d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d6bea4d20de847d0810bb45aa4064029",
              "IPY_MODEL_3acf2d79898a43a8a1a71264b9a94301",
              "IPY_MODEL_bb26c35228a34a3d95e163839b7b532b"
            ]
          }
        },
        "0078235319984b8297fda4f7ce2842d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6bea4d20de847d0810bb45aa4064029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb63e26fdaa94f74b204f53156a81d92",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dde7efbbcacd4f899533d7cdfa8ea979"
          }
        },
        "3acf2d79898a43a8a1a71264b9a94301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_867e3f5128644a9f8ffd5ec26ff29b28",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e66c357b22b4f019e7b136ecf900092"
          }
        },
        "bb26c35228a34a3d95e163839b7b532b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c411b23362254d678767d29954c19619",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 323B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ced0c004a4f4acd835c5a13dc3c28d6"
          }
        },
        "bb63e26fdaa94f74b204f53156a81d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dde7efbbcacd4f899533d7cdfa8ea979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "867e3f5128644a9f8ffd5ec26ff29b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e66c357b22b4f019e7b136ecf900092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c411b23362254d678767d29954c19619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ced0c004a4f4acd835c5a13dc3c28d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8868939f6ba48bf963a13eff4e75eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48da78faf4824f09b27e3e3e09ccd308",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac9f13c2948b42a6b617973222848905",
              "IPY_MODEL_372e7fabcaae445d87109d523cdf09fb",
              "IPY_MODEL_ad5a129aadfc49938560e76cc31aad44"
            ]
          }
        },
        "48da78faf4824f09b27e3e3e09ccd308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac9f13c2948b42a6b617973222848905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5a427875d3f45a08d61f485fc698a2b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5850ae67ecf5401eb22e8b49bc199be7"
          }
        },
        "372e7fabcaae445d87109d523cdf09fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_de90b9c46ce641b4a59fd0ccc4e48337",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a84e4711e514dd8ab26d00d81934d2c"
          }
        },
        "ad5a129aadfc49938560e76cc31aad44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79b5bd9e08a24965a80aa491ba77a792",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 2.67MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a523cf3624934462b4e875319ba9dd38"
          }
        },
        "e5a427875d3f45a08d61f485fc698a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5850ae67ecf5401eb22e8b49bc199be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de90b9c46ce641b4a59fd0ccc4e48337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a84e4711e514dd8ab26d00d81934d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79b5bd9e08a24965a80aa491ba77a792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a523cf3624934462b4e875319ba9dd38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "010c3447aefa4d8ca40db6dfd146fa2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6a23d4470e44d088b4e0a8ed4eddf0c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b2a8890e1774d23aa1233b09b339e5d",
              "IPY_MODEL_eb4cb39621904cf085f518849545776a",
              "IPY_MODEL_a343429de4b5450da89a46f337e2318c"
            ]
          }
        },
        "d6a23d4470e44d088b4e0a8ed4eddf0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b2a8890e1774d23aa1233b09b339e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_372b707273274fecbece36a876b1d76a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ceae8dc0a954fe9aa561ac20c9d0472"
          }
        },
        "eb4cb39621904cf085f518849545776a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5bc9fd4e76514b91bb75242a94a73e99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f537506a9a9b4fd5833a470447cedc98"
          }
        },
        "a343429de4b5450da89a46f337e2318c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dfc9ac079ebd4f9e886aa2256a78c8b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 10.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ad2cb8d79b94d4a9cc202f5bfb02553"
          }
        },
        "372b707273274fecbece36a876b1d76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ceae8dc0a954fe9aa561ac20c9d0472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bc9fd4e76514b91bb75242a94a73e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f537506a9a9b4fd5833a470447cedc98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfc9ac079ebd4f9e886aa2256a78c8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ad2cb8d79b94d4a9cc202f5bfb02553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saivarshittha/search-query-categorisation/blob/main/code/search_query_categorisation_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOTiqrtNvyy"
      },
      "source": [
        "# Install Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkhc10wNrGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ce15b1-6fdf-49ec-c5ae-51041c72cfd3"
      },
      "source": [
        "!pip install transformers\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 32.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 35.7 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 59.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaayBEV1kX3B",
        "outputId": "0f1991a7-aa53-463d-e69d-8dc31f1e5fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKd-Tj3hOMsZ"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dff = pd.read_csv(\"merged.csv\")\n",
        "dff.insert(loc=0, column='labell', value=dff['label'])\n",
        "dff.pop('label')\n",
        "dff=dff.rename(columns = {'labell':'label'})\n",
        "# dff.label.sub(1)\n",
        "dff.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WF9ALShyk3oG",
        "outputId": "9f59819c-5087-418b-8342-7ea38616e788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e9ba5d78-6349-4f6a-ac4f-1a99a5b8fcdb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>brooklyn 99 gambling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>instagram ochish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>douche nugget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>permainan yang cuma 1 mb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>#facebook2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9ba5d78-6349-4f6a-ac4f-1a99a5b8fcdb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9ba5d78-6349-4f6a-ac4f-1a99a5b8fcdb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9ba5d78-6349-4f6a-ac4f-1a99a5b8fcdb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   label                      text\n",
              "0      2      brooklyn 99 gambling\n",
              "1      4          instagram ochish\n",
              "2      0             douche nugget\n",
              "3      0  permainan yang cuma 1 mb\n",
              "4      4             #facebook2018"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dff.head"
      ],
      "metadata": {
        "id": "LYwE-YL6mpRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "676DPU1BOPdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c001a58-aa09-4451-f5bc-9966ab797bcd"
      },
      "source": [
        "# check class distribution\n",
        "dff['label'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    0.368989\n",
              "0    0.296928\n",
              "1    0.147987\n",
              "2    0.113497\n",
              "3    0.072599\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dff.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pg-v6vhayCNA",
        "outputId": "d533ce7d-c427-4ef9-deb3-1ed551592dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1826e835-6e18-402f-9464-7b781a7c303f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>brooklyn 99 gambling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>instagram ochish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>douche nugget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>permainan yang cuma 1 mb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>#facebook2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1826e835-6e18-402f-9464-7b781a7c303f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1826e835-6e18-402f-9464-7b781a7c303f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1826e835-6e18-402f-9464-7b781a7c303f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   label                      text\n",
              "0      2      brooklyn 99 gambling\n",
              "1      4          instagram ochish\n",
              "2      0             douche nugget\n",
              "3      0  permainan yang cuma 1 mb\n",
              "4      4             #facebook2018"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfhSPF5jOWb7"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(dff['text'], dff['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=dff['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7hsdLoCO7uB"
      },
      "source": [
        "# Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kY3gZjO2RE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "84ecf1217a80427794e015aaba15142e",
            "ab18609848524d60b560f98bf17956e9",
            "919ad4d604a24f25aa92f353c2cf9091",
            "06ebfc9954ba460899610a2735d0aa33",
            "131060a25c6c49768670232f2f3fc3b1",
            "61562f1fe3f0488091c53a616e03a3b4",
            "0134b480b71b4bd5a812b4c46f7a051e",
            "95caae28f57b4068a0d3d7785cc1baa2",
            "13f5c169b5184bd7a0f7bf28cee623eb",
            "5e91a5ef386b48619161737847b7f5d2",
            "0481ce386ddf4ab9a3265c38e8e1b8e0",
            "53d4f64da89148909592d87ba0f36e18",
            "2318fa58513146409eb8d99feb41542f",
            "aa6b61fc6eb14dd38662496d6d0b0f64",
            "0505de31b50b419fb0d56121b4b567c6",
            "c3b2cdd328d9486d8f579569802f3bb3",
            "27434cfa966047878a6468b3d60d0e86",
            "89bc47d095e042dca62a29ddb1111275",
            "5e492a2c387147bcbb8c242dcce8efd4",
            "4c93139262ef4914891df018e2d7dfa2",
            "e3391352b44e4495846f284a206babdb",
            "24cf45a32a534558899f4f6b549a82b9",
            "a4929bceae594505ae228f3706eddfcf",
            "0078235319984b8297fda4f7ce2842d2",
            "d6bea4d20de847d0810bb45aa4064029",
            "3acf2d79898a43a8a1a71264b9a94301",
            "bb26c35228a34a3d95e163839b7b532b",
            "bb63e26fdaa94f74b204f53156a81d92",
            "dde7efbbcacd4f899533d7cdfa8ea979",
            "867e3f5128644a9f8ffd5ec26ff29b28",
            "3e66c357b22b4f019e7b136ecf900092",
            "c411b23362254d678767d29954c19619",
            "6ced0c004a4f4acd835c5a13dc3c28d6",
            "b8868939f6ba48bf963a13eff4e75eb6",
            "48da78faf4824f09b27e3e3e09ccd308",
            "ac9f13c2948b42a6b617973222848905",
            "372e7fabcaae445d87109d523cdf09fb",
            "ad5a129aadfc49938560e76cc31aad44",
            "e5a427875d3f45a08d61f485fc698a2b",
            "5850ae67ecf5401eb22e8b49bc199be7",
            "de90b9c46ce641b4a59fd0ccc4e48337",
            "2a84e4711e514dd8ab26d00d81934d2c",
            "79b5bd9e08a24965a80aa491ba77a792",
            "a523cf3624934462b4e875319ba9dd38",
            "010c3447aefa4d8ca40db6dfd146fa2f",
            "d6a23d4470e44d088b4e0a8ed4eddf0c",
            "5b2a8890e1774d23aa1233b09b339e5d",
            "eb4cb39621904cf085f518849545776a",
            "a343429de4b5450da89a46f337e2318c",
            "372b707273274fecbece36a876b1d76a",
            "2ceae8dc0a954fe9aa561ac20c9d0472",
            "5bc9fd4e76514b91bb75242a94a73e99",
            "f537506a9a9b4fd5833a470447cedc98",
            "dfc9ac079ebd4f9e886aa2256a78c8b1",
            "3ad2cb8d79b94d4a9cc202f5bfb02553"
          ]
        },
        "outputId": "79f887ca-a99a-4aa1-c255-f25f17e7027e"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84ecf1217a80427794e015aaba15142e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53d4f64da89148909592d87ba0f36e18",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4929bceae594505ae228f3706eddfcf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8868939f6ba48bf963a13eff4e75eb6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "010c3447aefa4d8ca40db6dfd146fa2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAH73n39PHLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209f3f6c-7d35-4038-cdf0-57c340e8d0bd"
      },
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwbpeN_PMiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "e0f6ca49-9470-4405-aebc-314b796d8022"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f36ecbc9810>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "source": [
        "max_seq_len = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5S7DWaP2t6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f804a20b-4d26-478b-fe39-2bff67779c26"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUy9JKFYQYLp"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,5)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXS0IilRn9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7674b2-44bc-4e24-fda7-1ed2e08a19fd"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12jyHxZ2y8u3",
        "outputId": "f2145026-80ff-4f85-898c-10066b74dcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izY5xH5eR7Ur"
      },
      "source": [
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(class_weight = \"balanced\",classes = np.unique(train_labels),y= train_labels)\n",
        "# class_wts = dict(zip(np.unique(train_labels),class_wts))\n",
        "\n",
        "# print(class_wts)\n",
        "# class_weights = compute_class_weight(\n",
        "#                                         class_weight = \"balanced\",\n",
        "#                                         classes = np.unique(train_classes),\n",
        "#                                         y = train_classes                                                    \n",
        "#                                     )\n",
        "# class_weights = dict(zip(np.unique(train_classes), class_weights)),\n",
        "# class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1WvfY2vSGKi"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    # if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "    #   # Calculate elapsed time in minutes.\n",
        "    #   # elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "    #   # Report progress.\n",
        "    #   print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1USGTntS3TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a613b8-6abb-4b37-8dae-c8b905a44ba6"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.165\n",
            "Validation Loss: 0.720\n",
            "\n",
            " Epoch 2 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.827\n",
            "Validation Loss: 0.636\n",
            "\n",
            " Epoch 3 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.740\n",
            "Validation Loss: 0.587\n",
            "\n",
            " Epoch 4 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.696\n",
            "Validation Loss: 0.500\n",
            "\n",
            " Epoch 5 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.688\n",
            "Validation Loss: 0.474\n",
            "\n",
            " Epoch 6 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.667\n",
            "Validation Loss: 0.478\n",
            "\n",
            " Epoch 7 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.648\n",
            "Validation Loss: 0.464\n",
            "\n",
            " Epoch 8 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.638\n",
            "Validation Loss: 0.425\n",
            "\n",
            " Epoch 9 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.615\n",
            "Validation Loss: 0.512\n",
            "\n",
            " Epoch 10 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.622\n",
            "Validation Loss: 0.470\n",
            "\n",
            " Epoch 11 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.615\n",
            "Validation Loss: 0.406\n",
            "\n",
            " Epoch 12 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.609\n",
            "Validation Loss: 0.428\n",
            "\n",
            " Epoch 13 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.586\n",
            "Validation Loss: 0.447\n",
            "\n",
            " Epoch 14 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.589\n",
            "Validation Loss: 0.445\n",
            "\n",
            " Epoch 15 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.582\n",
            "Validation Loss: 0.407\n",
            "\n",
            " Epoch 16 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.584\n",
            "Validation Loss: 0.511\n",
            "\n",
            " Epoch 17 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.571\n",
            "Validation Loss: 0.380\n",
            "\n",
            " Epoch 18 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.563\n",
            "Validation Loss: 0.366\n",
            "\n",
            " Epoch 19 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.567\n",
            "Validation Loss: 0.395\n",
            "\n",
            " Epoch 20 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.557\n",
            "Validation Loss: 0.380\n",
            "\n",
            " Epoch 21 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.553\n",
            "Validation Loss: 0.366\n",
            "\n",
            " Epoch 22 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.555\n",
            "Validation Loss: 0.500\n",
            "\n",
            " Epoch 23 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.546\n",
            "Validation Loss: 0.355\n",
            "\n",
            " Epoch 24 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.547\n",
            "Validation Loss: 0.363\n",
            "\n",
            " Epoch 25 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.539\n",
            "Validation Loss: 0.395\n",
            "\n",
            " Epoch 26 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.544\n",
            "Validation Loss: 0.386\n",
            "\n",
            " Epoch 27 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.539\n",
            "Validation Loss: 0.402\n",
            "\n",
            " Epoch 28 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.541\n",
            "Validation Loss: 0.351\n",
            "\n",
            " Epoch 29 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.530\n",
            "Validation Loss: 0.351\n",
            "\n",
            " Epoch 30 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.528\n",
            "Validation Loss: 0.370\n",
            "\n",
            " Epoch 31 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.521\n",
            "Validation Loss: 0.468\n",
            "\n",
            " Epoch 32 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.517\n",
            "Validation Loss: 0.346\n",
            "\n",
            " Epoch 33 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.527\n",
            "Validation Loss: 0.364\n",
            "\n",
            " Epoch 34 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.517\n",
            "Validation Loss: 0.371\n",
            "\n",
            " Epoch 35 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.517\n",
            "Validation Loss: 0.377\n",
            "\n",
            " Epoch 36 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.508\n",
            "Validation Loss: 0.312\n",
            "\n",
            " Epoch 37 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.515\n",
            "Validation Loss: 0.350\n",
            "\n",
            " Epoch 38 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.521\n",
            "Validation Loss: 0.347\n",
            "\n",
            " Epoch 39 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.507\n",
            "Validation Loss: 0.381\n",
            "\n",
            " Epoch 40 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.497\n",
            "Validation Loss: 0.397\n",
            "\n",
            " Epoch 41 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.513\n",
            "Validation Loss: 0.346\n",
            "\n",
            " Epoch 42 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.507\n",
            "Validation Loss: 0.338\n",
            "\n",
            " Epoch 43 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.497\n",
            "Validation Loss: 0.389\n",
            "\n",
            " Epoch 44 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.494\n",
            "Validation Loss: 0.347\n",
            "\n",
            " Epoch 45 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.497\n",
            "Validation Loss: 0.313\n",
            "\n",
            " Epoch 46 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.490\n",
            "Validation Loss: 0.328\n",
            "\n",
            " Epoch 47 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.505\n",
            "Validation Loss: 0.318\n",
            "\n",
            " Epoch 48 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.493\n",
            "Validation Loss: 0.352\n",
            "\n",
            " Epoch 49 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.492\n",
            "Validation Loss: 0.340\n",
            "\n",
            " Epoch 50 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.489\n",
            "Validation Loss: 0.332\n",
            "\n",
            " Epoch 51 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.490\n",
            "Validation Loss: 0.327\n",
            "\n",
            " Epoch 52 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.484\n",
            "Validation Loss: 0.351\n",
            "\n",
            " Epoch 53 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.492\n",
            "Validation Loss: 0.314\n",
            "\n",
            " Epoch 54 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.484\n",
            "Validation Loss: 0.289\n",
            "\n",
            " Epoch 55 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.488\n",
            "Validation Loss: 0.327\n",
            "\n",
            " Epoch 56 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.482\n",
            "Validation Loss: 0.371\n",
            "\n",
            " Epoch 57 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.478\n",
            "Validation Loss: 0.399\n",
            "\n",
            " Epoch 58 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.482\n",
            "Validation Loss: 0.293\n",
            "\n",
            " Epoch 59 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.472\n",
            "Validation Loss: 0.315\n",
            "\n",
            " Epoch 60 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.471\n",
            "Validation Loss: 0.331\n",
            "\n",
            " Epoch 61 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.472\n",
            "Validation Loss: 0.363\n",
            "\n",
            " Epoch 62 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.472\n",
            "Validation Loss: 0.314\n",
            "\n",
            " Epoch 63 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.466\n",
            "Validation Loss: 0.329\n",
            "\n",
            " Epoch 64 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.469\n",
            "Validation Loss: 0.310\n",
            "\n",
            " Epoch 65 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.478\n",
            "Validation Loss: 0.338\n",
            "\n",
            " Epoch 66 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.472\n",
            "Validation Loss: 0.303\n",
            "\n",
            " Epoch 67 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.460\n",
            "Validation Loss: 0.369\n",
            "\n",
            " Epoch 68 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.468\n",
            "Validation Loss: 0.314\n",
            "\n",
            " Epoch 69 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.476\n",
            "Validation Loss: 0.309\n",
            "\n",
            " Epoch 70 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.464\n",
            "Validation Loss: 0.293\n",
            "\n",
            " Epoch 71 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.462\n",
            "Validation Loss: 0.286\n",
            "\n",
            " Epoch 72 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.456\n",
            "Validation Loss: 0.326\n",
            "\n",
            " Epoch 73 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.459\n",
            "Validation Loss: 0.298\n",
            "\n",
            " Epoch 74 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.461\n",
            "Validation Loss: 0.303\n",
            "\n",
            " Epoch 75 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.467\n",
            "Validation Loss: 0.313\n",
            "\n",
            " Epoch 76 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.474\n",
            "Validation Loss: 0.289\n",
            "\n",
            " Epoch 77 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.454\n",
            "Validation Loss: 0.276\n",
            "\n",
            " Epoch 78 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.459\n",
            "Validation Loss: 0.291\n",
            "\n",
            " Epoch 79 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.447\n",
            "Validation Loss: 0.305\n",
            "\n",
            " Epoch 80 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.457\n",
            "Validation Loss: 0.285\n",
            "\n",
            " Epoch 81 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.449\n",
            "Validation Loss: 0.302\n",
            "\n",
            " Epoch 82 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.457\n",
            "Validation Loss: 0.308\n",
            "\n",
            " Epoch 83 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.448\n",
            "Validation Loss: 0.326\n",
            "\n",
            " Epoch 84 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.448\n",
            "Validation Loss: 0.274\n",
            "\n",
            " Epoch 85 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.444\n",
            "Validation Loss: 0.283\n",
            "\n",
            " Epoch 86 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.463\n",
            "Validation Loss: 0.318\n",
            "\n",
            " Epoch 87 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.448\n",
            "Validation Loss: 0.309\n",
            "\n",
            " Epoch 88 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.453\n",
            "Validation Loss: 0.277\n",
            "\n",
            " Epoch 89 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.450\n",
            "Validation Loss: 0.285\n",
            "\n",
            " Epoch 90 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.450\n",
            "Validation Loss: 0.287\n",
            "\n",
            " Epoch 91 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.446\n",
            "Validation Loss: 0.311\n",
            "\n",
            " Epoch 92 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.445\n",
            "Validation Loss: 0.346\n",
            "\n",
            " Epoch 93 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.438\n",
            "Validation Loss: 0.303\n",
            "\n",
            " Epoch 94 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.436\n",
            "Validation Loss: 0.300\n",
            "\n",
            " Epoch 95 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.449\n",
            "Validation Loss: 0.277\n",
            "\n",
            " Epoch 96 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.435\n",
            "Validation Loss: 0.294\n",
            "\n",
            " Epoch 97 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.438\n",
            "Validation Loss: 0.266\n",
            "\n",
            " Epoch 98 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.434\n",
            "Validation Loss: 0.261\n",
            "\n",
            " Epoch 99 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.437\n",
            "Validation Loss: 0.267\n",
            "\n",
            " Epoch 100 / 100\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.444\n",
            "Validation Loss: 0.277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacxUyizS8d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd2e951-07f4-4763-bc61-37d2f9ca8f75"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1ObHZxTYSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e91e1ae-03b0-48c6-fb46-9c0e8707d932"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87      1821\n",
            "           1       0.89      0.92      0.90       908\n",
            "           2       0.94      0.89      0.91       696\n",
            "           3       0.82      0.92      0.86       445\n",
            "           4       0.94      0.91      0.92      2263\n",
            "\n",
            "    accuracy                           0.90      6133\n",
            "   macro avg       0.89      0.90      0.89      6133\n",
            "weighted avg       0.90      0.90      0.90      6133\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzLS7rHTp4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "20b055ac-5f26-4236-9618-efca2d75cc92"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1894596b-9659-4cdd-b4b1-815e1c840c64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1593</td>\n",
              "      <td>64</td>\n",
              "      <td>13</td>\n",
              "      <td>60</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42</td>\n",
              "      <td>831</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34</td>\n",
              "      <td>22</td>\n",
              "      <td>616</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>409</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>164</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>15</td>\n",
              "      <td>2058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1894596b-9659-4cdd-b4b1-815e1c840c64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1894596b-9659-4cdd-b4b1-815e1c840c64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1894596b-9659-4cdd-b4b1-815e1c840c64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "col_0     0    1    2    3     4\n",
              "row_0                           \n",
              "0      1593   64   13   60    91\n",
              "1        42  831    9   11    15\n",
              "2        34   22  616    6    18\n",
              "3        19    5    4  409     8\n",
              "4       164   10   16   15  2058"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tpc18kBZvgXk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}