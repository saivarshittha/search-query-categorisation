{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "search-query-categorisation-BERT.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b5fe4240e7e644ff9a02c9c1570524cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_338225f28dfa41438a4b70fecb668990",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_caf74a9d1a0a471a832e4950e0214b15",
              "IPY_MODEL_177928e3f4a44789919711cc5f590491",
              "IPY_MODEL_acd50eef33784f238ee7351e2a4737f8"
            ]
          }
        },
        "338225f28dfa41438a4b70fecb668990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "caf74a9d1a0a471a832e4950e0214b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_563f8d12bc4f4cdbbe4a0cc9c84afc0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e7c9e2601144080a6d0fb2054e4b702"
          }
        },
        "177928e3f4a44789919711cc5f590491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ae58a81870654703a70d38f4e0c61750",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47fec8d1ddae47959d3738946553c719"
          }
        },
        "acd50eef33784f238ee7351e2a4737f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3823440a66a34039a2cbb83a30402a9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 15.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6ab4f50f9cc409e8d200a51cf4487d0"
          }
        },
        "563f8d12bc4f4cdbbe4a0cc9c84afc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e7c9e2601144080a6d0fb2054e4b702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae58a81870654703a70d38f4e0c61750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47fec8d1ddae47959d3738946553c719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3823440a66a34039a2cbb83a30402a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6ab4f50f9cc409e8d200a51cf4487d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e4fc38b9cdd42c8a68dcb210f6754a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34a39e3b7bd54ababd690c064d90894e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_87f5cb79c69148e78855fc6cf4d69bc2",
              "IPY_MODEL_eae2ded8a05d41bda989b2f1fded2a39",
              "IPY_MODEL_2dbb00eb6d0a41de9ec720ba4df3cea0"
            ]
          }
        },
        "34a39e3b7bd54ababd690c064d90894e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87f5cb79c69148e78855fc6cf4d69bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efae555f0853467aa5dc16d31e50cd4e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3faaa1399fe14b098f39022d03f823c2"
          }
        },
        "eae2ded8a05d41bda989b2f1fded2a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7c69f4a57434ac3bbab79062cb91ac2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_beed52b477ff4fd8b4379d203460fa7c"
          }
        },
        "2dbb00eb6d0a41de9ec720ba4df3cea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_604e30e6b4ef4a7cb1c636311290ed18",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:08&lt;00:00, 54.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad111135f36b4d0bb7fb2113f457d647"
          }
        },
        "efae555f0853467aa5dc16d31e50cd4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3faaa1399fe14b098f39022d03f823c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7c69f4a57434ac3bbab79062cb91ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "beed52b477ff4fd8b4379d203460fa7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "604e30e6b4ef4a7cb1c636311290ed18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad111135f36b4d0bb7fb2113f457d647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30108daf62d9405c8a3af2f10af4bf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a6d6578dbce54acaa1e1a7e19f8b446a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3653fd9ecae941049af39e5d24995363",
              "IPY_MODEL_8d4d767b564e47d89e4b39aed7490f39",
              "IPY_MODEL_1df83dc1926e4048b4ef8d41f0ae5dd5"
            ]
          }
        },
        "a6d6578dbce54acaa1e1a7e19f8b446a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3653fd9ecae941049af39e5d24995363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ef192247a474cf081553edfcba8b620",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b55dc68b4d134911ad8d051927d95d10"
          }
        },
        "8d4d767b564e47d89e4b39aed7490f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83e9f4026865403c8e932a8bceb7a77b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e034eaec6894759bcf42407caecb287"
          }
        },
        "1df83dc1926e4048b4ef8d41f0ae5dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b06820f1e0c145409e93e6a53f7a1f41",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 948B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d7689425f254fd9833a75d126bb89ca"
          }
        },
        "7ef192247a474cf081553edfcba8b620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b55dc68b4d134911ad8d051927d95d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83e9f4026865403c8e932a8bceb7a77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e034eaec6894759bcf42407caecb287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b06820f1e0c145409e93e6a53f7a1f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d7689425f254fd9833a75d126bb89ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d39ad0ffffc545c3b784dea8f269ddb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da2b3b475b1b4aafbcf6c7d492efa560",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a683a108e52844cfaa21da3ad59dedd5",
              "IPY_MODEL_cfb5c718043b4a0da13d9f0dcd8e5a23",
              "IPY_MODEL_b0e42151679d401e83a5a86d44d3429a"
            ]
          }
        },
        "da2b3b475b1b4aafbcf6c7d492efa560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a683a108e52844cfaa21da3ad59dedd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68da6d0c925047198aa63124b6d3d214",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d3a36e0f13c47fc9bca30a1bc19dd82"
          }
        },
        "cfb5c718043b4a0da13d9f0dcd8e5a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_954617b6377a4f56a8b896e4c0c7ac0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f4c6cb569ebf44d6bebc69d53f7792c5"
          }
        },
        "b0e42151679d401e83a5a86d44d3429a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_89c7d21016c64c389493f7bfc8f766df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 2.04MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cbc3ddddc284b568232323536d9b4dd"
          }
        },
        "68da6d0c925047198aa63124b6d3d214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d3a36e0f13c47fc9bca30a1bc19dd82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "954617b6377a4f56a8b896e4c0c7ac0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f4c6cb569ebf44d6bebc69d53f7792c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89c7d21016c64c389493f7bfc8f766df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cbc3ddddc284b568232323536d9b4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cdc509dbc014126aae80bbe2d5f8389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6614355966724becb7cd5413ccf73606",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3938bd7bd7f409f997a5fe35c27fea8",
              "IPY_MODEL_02e5dd3a2897456fb7dad3b7850411d6",
              "IPY_MODEL_c23add175e424203a8c9a0af6a51b552"
            ]
          }
        },
        "6614355966724becb7cd5413ccf73606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3938bd7bd7f409f997a5fe35c27fea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c7ec3198e5b43fcbdb9a438511451b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d3f9e4e9fe14247b1f19fb7728bae73"
          }
        },
        "02e5dd3a2897456fb7dad3b7850411d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08cc3f60de2045949e1c3720188308fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_071ac2f199bc4300b02754097cd8279b"
          }
        },
        "c23add175e424203a8c9a0af6a51b552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_da2f7b79fe6a4c9093e3f0df11e66586",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 4.67MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2a9720c64bb4f81bc8245d71d72a675"
          }
        },
        "4c7ec3198e5b43fcbdb9a438511451b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d3f9e4e9fe14247b1f19fb7728bae73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08cc3f60de2045949e1c3720188308fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "071ac2f199bc4300b02754097cd8279b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da2f7b79fe6a4c9093e3f0df11e66586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2a9720c64bb4f81bc8245d71d72a675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saivarshittha/search-query-categorisation/blob/main/search_query_categorisation_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOTiqrtNvyy"
      },
      "source": [
        "# Install Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkhc10wNrGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "547bca1a-1192-4843-a424-a83a96a32fe8"
      },
      "source": [
        "!pip install transformers\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 68.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaayBEV1kX3B",
        "outputId": "da38e42e-7426-441e-ce78-908053827528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKd-Tj3hOMsZ"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dff = pd.read_csv(\"merged.csv\")\n",
        "dff.insert(loc=0, column='labell', value=dff['label'])\n",
        "dff.pop('label')\n",
        "dff=dff.rename(columns = {'labell':'label'})\n",
        "# dff.label.sub(1)\n",
        "dff.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WF9ALShyk3oG",
        "outputId": "6e630189-0db5-420f-d78f-ef08ca9fcc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6371f142-cf8e-4122-a5ea-65969b5243ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>brooklyn 99 gambling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>instagram ochish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>douche nugget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>permainan yang cuma 1 mb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>#facebook2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6371f142-cf8e-4122-a5ea-65969b5243ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6371f142-cf8e-4122-a5ea-65969b5243ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6371f142-cf8e-4122-a5ea-65969b5243ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   label                      text\n",
              "0      2      brooklyn 99 gambling\n",
              "1      4          instagram ochish\n",
              "2      0             douche nugget\n",
              "3      0  permainan yang cuma 1 mb\n",
              "4      4             #facebook2018"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dff.head"
      ],
      "metadata": {
        "id": "LYwE-YL6mpRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "676DPU1BOPdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fc3473-7663-4947-e8ab-3c860cd201b0"
      },
      "source": [
        "# check class distribution\n",
        "dff['label'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    0.368989\n",
              "0    0.296928\n",
              "1    0.147987\n",
              "2    0.113497\n",
              "3    0.072599\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dff.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pg-v6vhayCNA",
        "outputId": "0cc60e26-5ea3-4873-c0ba-7a6cda195584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4f05af1f-9960-4c66-bd5b-91fe65caa644\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>brooklyn 99 gambling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>instagram ochish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>douche nugget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>permainan yang cuma 1 mb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>#facebook2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f05af1f-9960-4c66-bd5b-91fe65caa644')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f05af1f-9960-4c66-bd5b-91fe65caa644 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f05af1f-9960-4c66-bd5b-91fe65caa644');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   label                      text\n",
              "0      2      brooklyn 99 gambling\n",
              "1      4          instagram ochish\n",
              "2      0             douche nugget\n",
              "3      0  permainan yang cuma 1 mb\n",
              "4      4             #facebook2018"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfhSPF5jOWb7"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(dff['text'], dff['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=dff['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7hsdLoCO7uB"
      },
      "source": [
        "# Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kY3gZjO2RE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "b5fe4240e7e644ff9a02c9c1570524cf",
            "338225f28dfa41438a4b70fecb668990",
            "caf74a9d1a0a471a832e4950e0214b15",
            "177928e3f4a44789919711cc5f590491",
            "acd50eef33784f238ee7351e2a4737f8",
            "563f8d12bc4f4cdbbe4a0cc9c84afc0a",
            "0e7c9e2601144080a6d0fb2054e4b702",
            "ae58a81870654703a70d38f4e0c61750",
            "47fec8d1ddae47959d3738946553c719",
            "3823440a66a34039a2cbb83a30402a9c",
            "a6ab4f50f9cc409e8d200a51cf4487d0",
            "6e4fc38b9cdd42c8a68dcb210f6754a9",
            "34a39e3b7bd54ababd690c064d90894e",
            "87f5cb79c69148e78855fc6cf4d69bc2",
            "eae2ded8a05d41bda989b2f1fded2a39",
            "2dbb00eb6d0a41de9ec720ba4df3cea0",
            "efae555f0853467aa5dc16d31e50cd4e",
            "3faaa1399fe14b098f39022d03f823c2",
            "b7c69f4a57434ac3bbab79062cb91ac2",
            "beed52b477ff4fd8b4379d203460fa7c",
            "604e30e6b4ef4a7cb1c636311290ed18",
            "ad111135f36b4d0bb7fb2113f457d647",
            "30108daf62d9405c8a3af2f10af4bf04",
            "a6d6578dbce54acaa1e1a7e19f8b446a",
            "3653fd9ecae941049af39e5d24995363",
            "8d4d767b564e47d89e4b39aed7490f39",
            "1df83dc1926e4048b4ef8d41f0ae5dd5",
            "7ef192247a474cf081553edfcba8b620",
            "b55dc68b4d134911ad8d051927d95d10",
            "83e9f4026865403c8e932a8bceb7a77b",
            "6e034eaec6894759bcf42407caecb287",
            "b06820f1e0c145409e93e6a53f7a1f41",
            "5d7689425f254fd9833a75d126bb89ca",
            "d39ad0ffffc545c3b784dea8f269ddb0",
            "da2b3b475b1b4aafbcf6c7d492efa560",
            "a683a108e52844cfaa21da3ad59dedd5",
            "cfb5c718043b4a0da13d9f0dcd8e5a23",
            "b0e42151679d401e83a5a86d44d3429a",
            "68da6d0c925047198aa63124b6d3d214",
            "7d3a36e0f13c47fc9bca30a1bc19dd82",
            "954617b6377a4f56a8b896e4c0c7ac0a",
            "f4c6cb569ebf44d6bebc69d53f7792c5",
            "89c7d21016c64c389493f7bfc8f766df",
            "4cbc3ddddc284b568232323536d9b4dd",
            "8cdc509dbc014126aae80bbe2d5f8389",
            "6614355966724becb7cd5413ccf73606",
            "b3938bd7bd7f409f997a5fe35c27fea8",
            "02e5dd3a2897456fb7dad3b7850411d6",
            "c23add175e424203a8c9a0af6a51b552",
            "4c7ec3198e5b43fcbdb9a438511451b1",
            "1d3f9e4e9fe14247b1f19fb7728bae73",
            "08cc3f60de2045949e1c3720188308fc",
            "071ac2f199bc4300b02754097cd8279b",
            "da2f7b79fe6a4c9093e3f0df11e66586",
            "d2a9720c64bb4f81bc8245d71d72a675"
          ]
        },
        "outputId": "b4fef0ba-6e8a-4372-b3c4-a096bb67848d"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5fe4240e7e644ff9a02c9c1570524cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e4fc38b9cdd42c8a68dcb210f6754a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30108daf62d9405c8a3af2f10af4bf04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d39ad0ffffc545c3b784dea8f269ddb0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cdc509dbc014126aae80bbe2d5f8389",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAH73n39PHLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5296ab-f950-4704-b301-4d953ccbe09f"
      },
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwbpeN_PMiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "ef9fa22e-d937-4a5f-d308-c749be4a577d"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9eb5ececd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "source": [
        "max_seq_len = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5S7DWaP2t6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a7700f-638f-4a0d-da3b-8fc0cf8176d0"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUy9JKFYQYLp"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,5)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXS0IilRn9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328a3c38-5996-4336-821c-0c5ea2ff0443"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( np.unique(train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12jyHxZ2y8u3",
        "outputId": "f10e5dc2-7692-484d-80a8-3feb268bd851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izY5xH5eR7Ur"
      },
      "source": [
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(class_weight = \"balanced\",classes = np.unique(train_labels),y= train_labels)\n",
        "# class_wts = dict(zip(np.unique(train_labels),class_wts))\n",
        "\n",
        "# print(class_wts)\n",
        "# class_weights = compute_class_weight(\n",
        "#                                         class_weight = \"balanced\",\n",
        "#                                         classes = np.unique(train_classes),\n",
        "#                                         y = train_classes                                                    \n",
        "#                                     )\n",
        "# class_weights = dict(zip(np.unique(train_classes), class_weights)),\n",
        "# class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1WvfY2vSGKi"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    # if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "    #   # Calculate elapsed time in minutes.\n",
        "    #   # elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "    #   # Report progress.\n",
        "    #   print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1USGTntS3TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8b7e14d-315e-426e-e99d-5f8da3758413"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 1.158\n",
            "Validation Loss: 0.782\n",
            "\n",
            " Epoch 2 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.817\n",
            "Validation Loss: 0.561\n",
            "\n",
            " Epoch 3 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.745\n",
            "Validation Loss: 0.504\n",
            "\n",
            " Epoch 4 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.721\n",
            "Validation Loss: 0.533\n",
            "\n",
            " Epoch 5 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.675\n",
            "Validation Loss: 0.517\n",
            "\n",
            " Epoch 6 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.655\n",
            "Validation Loss: 0.472\n",
            "\n",
            " Epoch 7 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.647\n",
            "Validation Loss: 0.591\n",
            "\n",
            " Epoch 8 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.644\n",
            "Validation Loss: 0.540\n",
            "\n",
            " Epoch 9 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.637\n",
            "Validation Loss: 0.463\n",
            "\n",
            " Epoch 10 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.615\n",
            "Validation Loss: 0.464\n",
            "\n",
            " Epoch 11 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.615\n",
            "Validation Loss: 0.414\n",
            "\n",
            " Epoch 12 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.595\n",
            "Validation Loss: 0.413\n",
            "\n",
            " Epoch 13 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.599\n",
            "Validation Loss: 0.396\n",
            "\n",
            " Epoch 14 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.594\n",
            "Validation Loss: 0.431\n",
            "\n",
            " Epoch 15 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.584\n",
            "Validation Loss: 0.549\n",
            "\n",
            " Epoch 16 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.588\n",
            "Validation Loss: 0.425\n",
            "\n",
            " Epoch 17 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.575\n",
            "Validation Loss: 0.439\n",
            "\n",
            " Epoch 18 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.574\n",
            "Validation Loss: 0.559\n",
            "\n",
            " Epoch 19 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.569\n",
            "Validation Loss: 0.441\n",
            "\n",
            " Epoch 20 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.566\n",
            "Validation Loss: 0.391\n",
            "\n",
            " Epoch 21 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.559\n",
            "Validation Loss: 0.448\n",
            "\n",
            " Epoch 22 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.552\n",
            "Validation Loss: 0.354\n",
            "\n",
            " Epoch 23 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.549\n",
            "Validation Loss: 0.355\n",
            "\n",
            " Epoch 24 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.540\n",
            "Validation Loss: 0.435\n",
            "\n",
            " Epoch 25 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.541\n",
            "Validation Loss: 0.362\n",
            "\n",
            " Epoch 26 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.538\n",
            "Validation Loss: 0.389\n",
            "\n",
            " Epoch 27 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.540\n",
            "Validation Loss: 0.361\n",
            "\n",
            " Epoch 28 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.526\n",
            "Validation Loss: 0.351\n",
            "\n",
            " Epoch 29 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.517\n",
            "Validation Loss: 0.358\n",
            "\n",
            " Epoch 30 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.525\n",
            "Validation Loss: 0.361\n",
            "\n",
            " Epoch 31 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.540\n",
            "Validation Loss: 0.451\n",
            "\n",
            " Epoch 32 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.524\n",
            "Validation Loss: 0.386\n",
            "\n",
            " Epoch 33 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.525\n",
            "Validation Loss: 0.364\n",
            "\n",
            " Epoch 34 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.517\n",
            "Validation Loss: 0.411\n",
            "\n",
            " Epoch 35 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.519\n",
            "Validation Loss: 0.417\n",
            "\n",
            " Epoch 36 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.510\n",
            "Validation Loss: 0.365\n",
            "\n",
            " Epoch 37 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.509\n",
            "Validation Loss: 0.324\n",
            "\n",
            " Epoch 38 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.519\n",
            "Validation Loss: 0.346\n",
            "\n",
            " Epoch 39 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.510\n",
            "Validation Loss: 0.427\n",
            "\n",
            " Epoch 40 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.502\n",
            "Validation Loss: 0.321\n",
            "\n",
            " Epoch 41 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.497\n",
            "Validation Loss: 0.374\n",
            "\n",
            " Epoch 42 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.503\n",
            "Validation Loss: 0.327\n",
            "\n",
            " Epoch 43 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.506\n",
            "Validation Loss: 0.324\n",
            "\n",
            " Epoch 44 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.504\n",
            "Validation Loss: 0.321\n",
            "\n",
            " Epoch 45 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.504\n",
            "Validation Loss: 0.310\n",
            "\n",
            " Epoch 46 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.507\n",
            "Validation Loss: 0.358\n",
            "\n",
            " Epoch 47 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.496\n",
            "Validation Loss: 0.323\n",
            "\n",
            " Epoch 48 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.497\n",
            "Validation Loss: 0.312\n",
            "\n",
            " Epoch 49 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.485\n",
            "Validation Loss: 0.389\n",
            "\n",
            " Epoch 50 / 50\n",
            "  Batch    50  of    895.\n",
            "  Batch   100  of    895.\n",
            "  Batch   150  of    895.\n",
            "  Batch   200  of    895.\n",
            "  Batch   250  of    895.\n",
            "  Batch   300  of    895.\n",
            "  Batch   350  of    895.\n",
            "  Batch   400  of    895.\n",
            "  Batch   450  of    895.\n",
            "  Batch   500  of    895.\n",
            "  Batch   550  of    895.\n",
            "  Batch   600  of    895.\n",
            "  Batch   650  of    895.\n",
            "  Batch   700  of    895.\n",
            "  Batch   750  of    895.\n",
            "  Batch   800  of    895.\n",
            "  Batch   850  of    895.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.494\n",
            "Validation Loss: 0.324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacxUyizS8d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c028fc37-6d38-4ed0-91a1-9f826b74ad6d"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1ObHZxTYSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c4f68e5-f8b2-4243-ed76-c144b9e83011"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.85      1821\n",
            "           1       0.90      0.89      0.89       908\n",
            "           2       0.88      0.90      0.89       696\n",
            "           3       0.78      0.89      0.83       445\n",
            "           4       0.96      0.88      0.92      2263\n",
            "\n",
            "    accuracy                           0.88      6133\n",
            "   macro avg       0.87      0.89      0.88      6133\n",
            "weighted avg       0.89      0.88      0.89      6133\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzLS7rHTp4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31af9f69-083a-4902-cff1-d27325f2da72"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-05a024d4-c4e9-4451-a25c-319c17249f66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1606</td>\n",
              "      <td>62</td>\n",
              "      <td>27</td>\n",
              "      <td>65</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>806</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34</td>\n",
              "      <td>15</td>\n",
              "      <td>627</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>397</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>214</td>\n",
              "      <td>10</td>\n",
              "      <td>31</td>\n",
              "      <td>23</td>\n",
              "      <td>1985</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05a024d4-c4e9-4451-a25c-319c17249f66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05a024d4-c4e9-4451-a25c-319c17249f66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05a024d4-c4e9-4451-a25c-319c17249f66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "col_0     0    1    2    3     4\n",
              "row_0                           \n",
              "0      1606   62   27   65    61\n",
              "1        62  806   19   14     7\n",
              "2        34   15  627   10    10\n",
              "3        30    4    9  397     5\n",
              "4       214   10   31   23  1985"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_classifier_model = model.load_state_dict(torch.load(path))\n",
        "query_classifier_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "915aKVoCl3Xs",
        "outputId": "45b0c101-32f8-4937-c6a0-684778ba10ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def prepare_data(input_text, tokenizer):\n",
        "    tokens_pred = tokenizer.batch_encode_plus(\n",
        "      val_text.tolist(),\n",
        "      max_length = 256,\n",
        "      pad_to_max_length=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "      )\n",
        "    return {'pred_seq' : torch.tensor(tokens_pred['input_ids']).to(device),\n",
        "    'pred_mask' : torch.tensor(tokens_pred['attention_mask']).to(device)\n",
        "    }\n",
        "\n",
        "def make_prediction(model, processed_data, classes=['Adult Content', 'Drugs related content', 'Gambling related content', 'Violence Related content', 'Entertainment Related content']):\n",
        "    probs = model(processed_data['pred_seq'], processed_data['pred_mask'])\n",
        "    probs = probs.detach().cpu().numpy()\n",
        "    return classes[np.argmax(probs, axis = 1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6PsxRNehNUm",
        "outputId": "cfade254-d638-407d-80ea-2a117b42d18f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe=[0,1,2,3,4]\n",
        "pros = model(prepare_data('beer price', tokenizer)['pred_seq'].to(device), prepare_data('beer price', tokenizer)['pred_mask'].to(device))\n",
        "pros = pros.detach().cpu().numpy()\n",
        "(np.argmax(pros))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "rzABMefawuSu",
        "outputId": "7ee51c7d-4fb0-4875-f288-c5021ca46928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-de7bee72dd33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclasse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beer price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beer price'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-01e8bc9bf12c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         )\n\u001b[1;32m    996\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.49 GiB (GPU 0; 11.17 GiB total capacity; 9.84 GiB already allocated; 547.81 MiB free; 10.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = input('Enter search query here: ')\n",
        "processed_data = prepare_data(input_text, tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCN_LB_tkTvg",
        "outputId": "2da6e5db-417b-445d-9080-0e8eed514dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter search query here: i love weed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = make_prediction(query_classifier_model, processed_data=processed_data)\n",
        "print(f\"Predicted Category: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Dmod8DtvkWMC",
        "outputId": "95f7ed34-4a7a-45a9-e4f1-4777e6603637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-bba4e14db4a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_classifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted Category: {result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-ff38b116a6f0>\u001b[0m in \u001b[0;36mmake_prediction\u001b[0;34m(model, processed_data, classes)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Adult Content'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Drugs related content'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Gambling related content'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Violence Related content'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Entertainment Related content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '_IncompatibleKeys' object is not callable"
          ]
        }
      ]
    }
  ]
}